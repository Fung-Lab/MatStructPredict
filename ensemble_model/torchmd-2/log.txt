Loading dataset to cpu
Using PyTorch automatic mixed-precision
GPU is available: True, Quantity: None
Dataset(s) used:
Dataset length: ('train', 177907)
Dataset length: ('val', 9363)
Dataset length: ('test', 0)
Data(n_atoms=[1], pos=[8, 3], cell=[1, 3, 3], structure_id=[1], z=[8], u=[1, 3], y=[1, 1], forces=[8, 3], stress=[1, 3, 3], x=[8, 100])
tensor(3)
tensor([-40.4184])

--------------------------------------------------------------------------
               Layer.Parameter    Param Tensor Shape              Param #
--------------------------------------------------------------------------
              embedding.weight            [100, 128]                12800
      distance_expansion.means                  [50]                   50
      distance_expansion.betas                  [50]                   50
neighbor_embedding.embedding.weight            [100, 128]                12800
neighbor_embedding.distance_proj.weight             [128, 50]                 6400
neighbor_embedding.distance_proj.bias                 [128]                  128
neighbor_embedding.combine.weight            [128, 256]                32768
neighbor_embedding.combine.bias                 [128]                  128
attention_layers.0.layernorm.weight                 [128]                  128
attention_layers.0.layernorm.bias                 [128]                  128
attention_layers.0.q_proj.weight            [128, 128]                16384
attention_layers.0.q_proj.bias                 [128]                  128
attention_layers.0.k_proj.weight            [128, 128]                16384
attention_layers.0.k_proj.bias                 [128]                  128
attention_layers.0.v_proj.weight            [384, 128]                49152
attention_layers.0.v_proj.bias                 [384]                  384
attention_layers.0.o_proj.weight            [384, 128]                49152
attention_layers.0.o_proj.bias                 [384]                  384
attention_layers.0.vec_proj.weight            [384, 128]                49152
attention_layers.0.dk_proj.weight             [128, 50]                 6400
attention_layers.0.dk_proj.bias                 [128]                  128
attention_layers.0.dv_proj.weight             [384, 50]                19200
attention_layers.0.dv_proj.bias                 [384]                  384
attention_layers.1.layernorm.weight                 [128]                  128
attention_layers.1.layernorm.bias                 [128]                  128
attention_layers.1.q_proj.weight            [128, 128]                16384
attention_layers.1.q_proj.bias                 [128]                  128
attention_layers.1.k_proj.weight            [128, 128]                16384
attention_layers.1.k_proj.bias                 [128]                  128
attention_layers.1.v_proj.weight            [384, 128]                49152
attention_layers.1.v_proj.bias                 [384]                  384
attention_layers.1.o_proj.weight            [384, 128]                49152
attention_layers.1.o_proj.bias                 [384]                  384
attention_layers.1.vec_proj.weight            [384, 128]                49152
attention_layers.1.dk_proj.weight             [128, 50]                 6400
attention_layers.1.dk_proj.bias                 [128]                  128
attention_layers.1.dv_proj.weight             [384, 50]                19200
attention_layers.1.dv_proj.bias                 [384]                  384
attention_layers.2.layernorm.weight                 [128]                  128
attention_layers.2.layernorm.bias                 [128]                  128
attention_layers.2.q_proj.weight            [128, 128]                16384
attention_layers.2.q_proj.bias                 [128]                  128
attention_layers.2.k_proj.weight            [128, 128]                16384
attention_layers.2.k_proj.bias                 [128]                  128
attention_layers.2.v_proj.weight            [384, 128]                49152
attention_layers.2.v_proj.bias                 [384]                  384
attention_layers.2.o_proj.weight            [384, 128]                49152
attention_layers.2.o_proj.bias                 [384]                  384
attention_layers.2.vec_proj.weight            [384, 128]                49152
attention_layers.2.dk_proj.weight             [128, 50]                 6400
attention_layers.2.dk_proj.bias                 [128]                  128
attention_layers.2.dv_proj.weight             [384, 50]                19200
attention_layers.2.dv_proj.bias                 [384]                  384
attention_layers.3.layernorm.weight                 [128]                  128
attention_layers.3.layernorm.bias                 [128]                  128
attention_layers.3.q_proj.weight            [128, 128]                16384
attention_layers.3.q_proj.bias                 [128]                  128
attention_layers.3.k_proj.weight            [128, 128]                16384
attention_layers.3.k_proj.bias                 [128]                  128
attention_layers.3.v_proj.weight            [384, 128]                49152
attention_layers.3.v_proj.bias                 [384]                  384
attention_layers.3.o_proj.weight            [384, 128]                49152
attention_layers.3.o_proj.bias                 [384]                  384
attention_layers.3.vec_proj.weight            [384, 128]                49152
attention_layers.3.dk_proj.weight             [128, 50]                 6400
attention_layers.3.dk_proj.bias                 [128]                  128
attention_layers.3.dv_proj.weight             [384, 50]                19200
attention_layers.3.dv_proj.bias                 [384]                  384
attention_layers.4.layernorm.weight                 [128]                  128
attention_layers.4.layernorm.bias                 [128]                  128
attention_layers.4.q_proj.weight            [128, 128]                16384
attention_layers.4.q_proj.bias                 [128]                  128
attention_layers.4.k_proj.weight            [128, 128]                16384
attention_layers.4.k_proj.bias                 [128]                  128
attention_layers.4.v_proj.weight            [384, 128]                49152
attention_layers.4.v_proj.bias                 [384]                  384
attention_layers.4.o_proj.weight            [384, 128]                49152
attention_layers.4.o_proj.bias                 [384]                  384
attention_layers.4.vec_proj.weight            [384, 128]                49152
attention_layers.4.dk_proj.weight             [128, 50]                 6400
attention_layers.4.dk_proj.bias                 [128]                  128
attention_layers.4.dv_proj.weight             [384, 50]                19200
attention_layers.4.dv_proj.bias                 [384]                  384
attention_layers.5.layernorm.weight                 [128]                  128
attention_layers.5.layernorm.bias                 [128]                  128
attention_layers.5.q_proj.weight            [128, 128]                16384
attention_layers.5.q_proj.bias                 [128]                  128
attention_layers.5.k_proj.weight            [128, 128]                16384
attention_layers.5.k_proj.bias                 [128]                  128
attention_layers.5.v_proj.weight            [384, 128]                49152
attention_layers.5.v_proj.bias                 [384]                  384
attention_layers.5.o_proj.weight            [384, 128]                49152
attention_layers.5.o_proj.bias                 [384]                  384
attention_layers.5.vec_proj.weight            [384, 128]                49152
attention_layers.5.dk_proj.weight             [128, 50]                 6400
attention_layers.5.dk_proj.bias                 [128]                  128
attention_layers.5.dv_proj.weight             [384, 50]                19200
attention_layers.5.dv_proj.bias                 [384]                  384
attention_layers.6.layernorm.weight                 [128]                  128
attention_layers.6.layernorm.bias                 [128]                  128
attention_layers.6.q_proj.weight            [128, 128]                16384
attention_layers.6.q_proj.bias                 [128]                  128
attention_layers.6.k_proj.weight            [128, 128]                16384
attention_layers.6.k_proj.bias                 [128]                  128
attention_layers.6.v_proj.weight            [384, 128]                49152
attention_layers.6.v_proj.bias                 [384]                  384
attention_layers.6.o_proj.weight            [384, 128]                49152
attention_layers.6.o_proj.bias                 [384]                  384
attention_layers.6.vec_proj.weight            [384, 128]                49152
attention_layers.6.dk_proj.weight             [128, 50]                 6400
attention_layers.6.dk_proj.bias                 [128]                  128
attention_layers.6.dv_proj.weight             [384, 50]                19200
attention_layers.6.dv_proj.bias                 [384]                  384
attention_layers.7.layernorm.weight                 [128]                  128
attention_layers.7.layernorm.bias                 [128]                  128
attention_layers.7.q_proj.weight            [128, 128]                16384
attention_layers.7.q_proj.bias                 [128]                  128
attention_layers.7.k_proj.weight            [128, 128]                16384
attention_layers.7.k_proj.bias                 [128]                  128
attention_layers.7.v_proj.weight            [384, 128]                49152
attention_layers.7.v_proj.bias                 [384]                  384
attention_layers.7.o_proj.weight            [384, 128]                49152
attention_layers.7.o_proj.bias                 [384]                  384
attention_layers.7.vec_proj.weight            [384, 128]                49152
attention_layers.7.dk_proj.weight             [128, 50]                 6400
attention_layers.7.dk_proj.bias                 [128]                  128
attention_layers.7.dv_proj.weight             [384, 50]                19200
attention_layers.7.dv_proj.bias                 [384]                  384
               out_norm.weight                 [128]                  128
                 out_norm.bias                 [128]                  128
        post_lin_list.0.weight             [64, 128]                 8192
          post_lin_list.0.bias                  [64]                   64
        post_lin_list.1.weight               [1, 64]                   64
          post_lin_list.1.bias                   [1]                    1
--------------------------------------------------------------------------
Total params: 1734629
Trainable params: 1734629
Non-trainable params: 0
Attempting to load checkpoint...
Recent checkpoint loaded successfully.
Settings: 
{'dataset': {'additional_attributes': ['forces', 'stress'],
             'data_format': 'json',
             'dataset_device': 'cpu',
             'name': 'MP_data_forces',
             'num_workers': 0,
             'prediction_level': 'graph',
             'preprocess_params': {'all_neighbors': True,
                                   'cutoff_radius': 8.0,
                                   'edge_calc_method': 'ocp',
                                   'edge_dim': 50,
                                   'n_neighbors': 250,
                                   'node_dim': 100,
                                   'node_representation': 'onehot',
                                   'num_offsets': 2,
                                   'preprocess_edge_features': False,
                                   'preprocess_edges': False,
                                   'preprocess_node_features': True,
                                   'self_loop': True},
             'processed': True,
             'pt_path': 'data/mp_data_forces/',
             'src': '/global/cfs/projectdirs/m3641/Shared/Materials_datasets/MP_data_forces/raw/data.json',
             'target_path': None,
             'test_ratio': 0.0,
             'train_ratio': 0.95,
             'transforms': [{'args': {'index': -1},
                             'name': 'GetY',
                             'otf': True}],
             'val_ratio': 0.05,
             'verbose': True},
 'model': {'activation': 'silu',
           'aggr': 'add',
           'attn_activation': 'silu',
           'dropout_rate': 0.0,
           'gradient': True,
           'hidden_channels': 128,
           'model_ensemble': 1,
           'name': 'torchmd_etEarly',
           'num_heads': 8,
           'num_layers': 8,
           'num_post_layers': 1,
           'num_rbf': 50,
           'otf_edge_attr': True,
           'otf_edge_index': True,
           'otf_node_attr': False,
           'pool': 'global_add_pool',
           'pool_order': 'late',
           'post_hidden_channels': 64,
           'prediction_level': 'graph'},
 'optim': {'batch_size': 32,
           'batch_tqdm': False,
           'clip_grad_norm': 10,
           'loss': {'loss_args': {'weight_energy': 0.01,
                                  'weight_force': 50.0,
                                  'weight_stress': 50.0},
                    'loss_type': 'ForceStressLoss'},
           'lr': 0.0001,
           'max_checkpoint_epochs': 0,
           'max_epochs': 400,
           'optimizer': {'optimizer_args': {}, 'optimizer_type': 'AdamW'},
           'scheduler': {'scheduler_args': {'factor': 0.8,
                                            'min_lr': 1e-05,
                                            'mode': 'min',
                                            'patience': 10,
                                            'threshold': 0.0002},
                         'scheduler_type': 'ReduceLROnPlateau'},
           'verbosity': 1},
 'submit': False,
 'task': {'checkpoint_path': 'results/torchmd-2-part1/checkpoint_0/checkpoint.pt',
          'continue_job': True,
          'identifier': 'matstructpredict-torchmd-2',
          'load_training_state': True,
          'log_id': '2024-02-27-06-40-59-305',
          'model_save_frequency': 1,
          'output_frequency': 1,
          'parallel': False,
          'run_mode': 'train',
          'save_dir': None,
          'seed': 42419442,
          'use_amp': True,
          'write_output': ['val']},
 'trainer': 'property'}
Starting regular training
Running for 45 epochs on TorchMD_ET model
Epoch: 0355, Learning Rate: 0.000021, Training Error: 1.79281, Val Error: 3.49408, Time per epoch (s): 1742.37452
Saving prediction results for epoch 356 to: /results/2024-02-27-06-41-04-715-matstructpredict-torchmd-2/train_results/
Saved val error: 3.59142
Epoch: 0356, Learning Rate: 0.000021, Training Error: 1.80236, Val Error: 3.65863, Time per epoch (s): 1721.22535
Epoch: 0357, Learning Rate: 0.000021, Training Error: 1.80101, Val Error: 3.67888, Time per epoch (s): 1717.84081
Epoch: 0358, Learning Rate: 0.000021, Training Error: 1.80084, Val Error: 3.50010, Time per epoch (s): 1719.49765
Epoch: 0359, Learning Rate: 0.000021, Training Error: 1.78879, Val Error: 3.76381, Time per epoch (s): 1719.45244
Epoch: 0360, Learning Rate: 0.000021, Training Error: 1.81458, Val Error: 3.66469, Time per epoch (s): 1722.25712
Epoch: 0361, Learning Rate: 0.000021, Training Error: 1.80172, Val Error: 3.73277, Time per epoch (s): 1720.26922
Epoch: 0362, Learning Rate: 0.000021, Training Error: 1.80282, Val Error: 3.71480, Time per epoch (s): 1719.81829
Epoch: 0363, Learning Rate: 0.000021, Training Error: 1.80230, Val Error: 3.56827, Time per epoch (s): 1718.08061
Epoch: 0364, Learning Rate: 0.000021, Training Error: 1.78635, Val Error: 3.72200, Time per epoch (s): 1713.31982
Epoch: 0365, Learning Rate: 0.000021, Training Error: 1.78936, Val Error: 3.58011, Time per epoch (s): 1714.36159
Epoch: 0366, Learning Rate: 0.000017, Training Error: 1.76436, Val Error: 3.73017, Time per epoch (s): 1714.14950
Epoch: 0367, Learning Rate: 0.000017, Training Error: 1.75612, Val Error: 3.60620, Time per epoch (s): 1715.24902
Epoch: 0368, Learning Rate: 0.000017, Training Error: 1.73538, Val Error: 3.79240, Time per epoch (s): 1712.93931
Epoch: 0369, Learning Rate: 0.000017, Training Error: 1.74458, Val Error: 3.63608, Time per epoch (s): 1712.08285
Epoch: 0370, Learning Rate: 0.000017, Training Error: 1.73386, Val Error: 3.66138, Time per epoch (s): 1715.52692
Epoch: 0371, Learning Rate: 0.000017, Training Error: 1.73660, Val Error: 3.66681, Time per epoch (s): 1720.01285
Epoch: 0372, Learning Rate: 0.000017, Training Error: 1.73210, Val Error: 3.55043, Time per epoch (s): 1720.14167
Epoch: 0373, Learning Rate: 0.000017, Training Error: 1.73750, Val Error: 3.58407, Time per epoch (s): 1722.65397
Epoch: 0374, Learning Rate: 0.000017, Training Error: 1.71748, Val Error: 3.59205, Time per epoch (s): 1717.45899
Epoch: 0375, Learning Rate: 0.000017, Training Error: 1.73258, Val Error: 3.53678, Time per epoch (s): 1716.11043
Epoch: 0376, Learning Rate: 0.000017, Training Error: 1.74032, Val Error: 3.84873, Time per epoch (s): 1722.68752
Epoch: 0377, Learning Rate: 0.000017, Training Error: 1.71619, Val Error: 3.61033, Time per epoch (s): 1722.31376
Epoch: 0378, Learning Rate: 0.000017, Training Error: 1.72969, Val Error: 3.56878, Time per epoch (s): 1722.14193
Epoch: 0379, Learning Rate: 0.000017, Training Error: 1.74149, Val Error: 3.48529, Time per epoch (s): 1715.44121
Saving prediction results for epoch 380 to: /results/2024-02-27-06-41-04-715-matstructpredict-torchmd-2/train_results/
Saved val error: 3.58493
Epoch: 0380, Learning Rate: 0.000017, Training Error: 1.70970, Val Error: 3.55986, Time per epoch (s): 1713.32087
Epoch: 0381, Learning Rate: 0.000017, Training Error: 1.73122, Val Error: 3.60072, Time per epoch (s): 1714.90159
Epoch: 0382, Learning Rate: 0.000017, Training Error: 1.73504, Val Error: 3.49746, Time per epoch (s): 1714.24695
Epoch: 0383, Learning Rate: 0.000017, Training Error: 1.72932, Val Error: 3.62410, Time per epoch (s): 1714.05526
Epoch: 0384, Learning Rate: 0.000017, Training Error: 1.75390, Val Error: 3.57631, Time per epoch (s): 1724.29259
Epoch: 0385, Learning Rate: 0.000017, Training Error: 1.71895, Val Error: 3.70328, Time per epoch (s): 1713.39826
Epoch: 0386, Learning Rate: 0.000017, Training Error: 1.71835, Val Error: 3.61309, Time per epoch (s): 1712.33048
Epoch: 0387, Learning Rate: 0.000017, Training Error: 1.73590, Val Error: 3.56054, Time per epoch (s): 1716.10468
Epoch: 0388, Learning Rate: 0.000017, Training Error: 1.72154, Val Error: 3.42557, Time per epoch (s): 1714.83542
Saving prediction results for epoch 389 to: /results/2024-02-27-06-41-04-715-matstructpredict-torchmd-2/train_results/
Saved val error: 3.59648
Epoch: 0389, Learning Rate: 0.000017, Training Error: 1.73094, Val Error: 3.60119, Time per epoch (s): 1714.82688
Epoch: 0390, Learning Rate: 0.000017, Training Error: 1.72367, Val Error: 3.61148, Time per epoch (s): 1714.56139
Epoch: 0391, Learning Rate: 0.000017, Training Error: 1.72680, Val Error: 3.53000, Time per epoch (s): 1710.83403
Epoch: 0392, Learning Rate: 0.000013, Training Error: 1.70235, Val Error: 3.49451, Time per epoch (s): 1716.87853
Epoch: 0393, Learning Rate: 0.000013, Training Error: 1.67747, Val Error: 3.54634, Time per epoch (s): 1712.36265
Epoch: 0394, Learning Rate: 0.000013, Training Error: 1.66230, Val Error: 3.64256, Time per epoch (s): 1715.80141
Epoch: 0395, Learning Rate: 0.000013, Training Error: 1.67697, Val Error: 3.55408, Time per epoch (s): 1712.76139
Epoch: 0396, Learning Rate: 0.000013, Training Error: 1.68907, Val Error: 3.57063, Time per epoch (s): 1705.17453
Epoch: 0397, Learning Rate: 0.000013, Training Error: 1.68135, Val Error: 3.62803, Time per epoch (s): 1707.71917
Epoch: 0398, Learning Rate: 0.000013, Training Error: 1.64798, Val Error: 3.51839, Time per epoch (s): 1709.63998
Epoch: 0399, Learning Rate: 0.000013, Training Error: 1.67410, Val Error: 3.51566, Time per epoch (s): 1710.89723
Final Losses: 
Saved val error: 3.56683

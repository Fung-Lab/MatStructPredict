Loading dataset to cpu
Using PyTorch automatic mixed-precision
GPU is available: True, Quantity: None
Dataset(s) used:
Dataset length: ('train', 177907)
Dataset length: ('val', 9363)
Dataset length: ('test', 0)
Data(n_atoms=[1], pos=[4, 3], cell=[1, 3, 3], structure_id=[1], z=[4], u=[1, 3], y=[1, 1], forces=[4, 3], stress=[1, 3, 3], x=[4, 100])
tensor(20)
tensor([-9.5704])

--------------------------------------------------------------------------
               Layer.Parameter    Param Tensor Shape              Param #
--------------------------------------------------------------------------
              embedding.weight            [100, 128]                12800
      distance_expansion.means                  [50]                   50
      distance_expansion.betas                  [50]                   50
neighbor_embedding.embedding.weight            [100, 128]                12800
neighbor_embedding.distance_proj.weight             [128, 50]                 6400
neighbor_embedding.distance_proj.bias                 [128]                  128
neighbor_embedding.combine.weight            [128, 256]                32768
neighbor_embedding.combine.bias                 [128]                  128
attention_layers.0.layernorm.weight                 [128]                  128
attention_layers.0.layernorm.bias                 [128]                  128
attention_layers.0.q_proj.weight            [128, 128]                16384
attention_layers.0.q_proj.bias                 [128]                  128
attention_layers.0.k_proj.weight            [128, 128]                16384
attention_layers.0.k_proj.bias                 [128]                  128
attention_layers.0.v_proj.weight            [384, 128]                49152
attention_layers.0.v_proj.bias                 [384]                  384
attention_layers.0.o_proj.weight            [384, 128]                49152
attention_layers.0.o_proj.bias                 [384]                  384
attention_layers.0.vec_proj.weight            [384, 128]                49152
attention_layers.0.dk_proj.weight             [128, 50]                 6400
attention_layers.0.dk_proj.bias                 [128]                  128
attention_layers.0.dv_proj.weight             [384, 50]                19200
attention_layers.0.dv_proj.bias                 [384]                  384
attention_layers.1.layernorm.weight                 [128]                  128
attention_layers.1.layernorm.bias                 [128]                  128
attention_layers.1.q_proj.weight            [128, 128]                16384
attention_layers.1.q_proj.bias                 [128]                  128
attention_layers.1.k_proj.weight            [128, 128]                16384
attention_layers.1.k_proj.bias                 [128]                  128
attention_layers.1.v_proj.weight            [384, 128]                49152
attention_layers.1.v_proj.bias                 [384]                  384
attention_layers.1.o_proj.weight            [384, 128]                49152
attention_layers.1.o_proj.bias                 [384]                  384
attention_layers.1.vec_proj.weight            [384, 128]                49152
attention_layers.1.dk_proj.weight             [128, 50]                 6400
attention_layers.1.dk_proj.bias                 [128]                  128
attention_layers.1.dv_proj.weight             [384, 50]                19200
attention_layers.1.dv_proj.bias                 [384]                  384
attention_layers.2.layernorm.weight                 [128]                  128
attention_layers.2.layernorm.bias                 [128]                  128
attention_layers.2.q_proj.weight            [128, 128]                16384
attention_layers.2.q_proj.bias                 [128]                  128
attention_layers.2.k_proj.weight            [128, 128]                16384
attention_layers.2.k_proj.bias                 [128]                  128
attention_layers.2.v_proj.weight            [384, 128]                49152
attention_layers.2.v_proj.bias                 [384]                  384
attention_layers.2.o_proj.weight            [384, 128]                49152
attention_layers.2.o_proj.bias                 [384]                  384
attention_layers.2.vec_proj.weight            [384, 128]                49152
attention_layers.2.dk_proj.weight             [128, 50]                 6400
attention_layers.2.dk_proj.bias                 [128]                  128
attention_layers.2.dv_proj.weight             [384, 50]                19200
attention_layers.2.dv_proj.bias                 [384]                  384
attention_layers.3.layernorm.weight                 [128]                  128
attention_layers.3.layernorm.bias                 [128]                  128
attention_layers.3.q_proj.weight            [128, 128]                16384
attention_layers.3.q_proj.bias                 [128]                  128
attention_layers.3.k_proj.weight            [128, 128]                16384
attention_layers.3.k_proj.bias                 [128]                  128
attention_layers.3.v_proj.weight            [384, 128]                49152
attention_layers.3.v_proj.bias                 [384]                  384
attention_layers.3.o_proj.weight            [384, 128]                49152
attention_layers.3.o_proj.bias                 [384]                  384
attention_layers.3.vec_proj.weight            [384, 128]                49152
attention_layers.3.dk_proj.weight             [128, 50]                 6400
attention_layers.3.dk_proj.bias                 [128]                  128
attention_layers.3.dv_proj.weight             [384, 50]                19200
attention_layers.3.dv_proj.bias                 [384]                  384
attention_layers.4.layernorm.weight                 [128]                  128
attention_layers.4.layernorm.bias                 [128]                  128
attention_layers.4.q_proj.weight            [128, 128]                16384
attention_layers.4.q_proj.bias                 [128]                  128
attention_layers.4.k_proj.weight            [128, 128]                16384
attention_layers.4.k_proj.bias                 [128]                  128
attention_layers.4.v_proj.weight            [384, 128]                49152
attention_layers.4.v_proj.bias                 [384]                  384
attention_layers.4.o_proj.weight            [384, 128]                49152
attention_layers.4.o_proj.bias                 [384]                  384
attention_layers.4.vec_proj.weight            [384, 128]                49152
attention_layers.4.dk_proj.weight             [128, 50]                 6400
attention_layers.4.dk_proj.bias                 [128]                  128
attention_layers.4.dv_proj.weight             [384, 50]                19200
attention_layers.4.dv_proj.bias                 [384]                  384
attention_layers.5.layernorm.weight                 [128]                  128
attention_layers.5.layernorm.bias                 [128]                  128
attention_layers.5.q_proj.weight            [128, 128]                16384
attention_layers.5.q_proj.bias                 [128]                  128
attention_layers.5.k_proj.weight            [128, 128]                16384
attention_layers.5.k_proj.bias                 [128]                  128
attention_layers.5.v_proj.weight            [384, 128]                49152
attention_layers.5.v_proj.bias                 [384]                  384
attention_layers.5.o_proj.weight            [384, 128]                49152
attention_layers.5.o_proj.bias                 [384]                  384
attention_layers.5.vec_proj.weight            [384, 128]                49152
attention_layers.5.dk_proj.weight             [128, 50]                 6400
attention_layers.5.dk_proj.bias                 [128]                  128
attention_layers.5.dv_proj.weight             [384, 50]                19200
attention_layers.5.dv_proj.bias                 [384]                  384
attention_layers.6.layernorm.weight                 [128]                  128
attention_layers.6.layernorm.bias                 [128]                  128
attention_layers.6.q_proj.weight            [128, 128]                16384
attention_layers.6.q_proj.bias                 [128]                  128
attention_layers.6.k_proj.weight            [128, 128]                16384
attention_layers.6.k_proj.bias                 [128]                  128
attention_layers.6.v_proj.weight            [384, 128]                49152
attention_layers.6.v_proj.bias                 [384]                  384
attention_layers.6.o_proj.weight            [384, 128]                49152
attention_layers.6.o_proj.bias                 [384]                  384
attention_layers.6.vec_proj.weight            [384, 128]                49152
attention_layers.6.dk_proj.weight             [128, 50]                 6400
attention_layers.6.dk_proj.bias                 [128]                  128
attention_layers.6.dv_proj.weight             [384, 50]                19200
attention_layers.6.dv_proj.bias                 [384]                  384
attention_layers.7.layernorm.weight                 [128]                  128
attention_layers.7.layernorm.bias                 [128]                  128
attention_layers.7.q_proj.weight            [128, 128]                16384
attention_layers.7.q_proj.bias                 [128]                  128
attention_layers.7.k_proj.weight            [128, 128]                16384
attention_layers.7.k_proj.bias                 [128]                  128
attention_layers.7.v_proj.weight            [384, 128]                49152
attention_layers.7.v_proj.bias                 [384]                  384
attention_layers.7.o_proj.weight            [384, 128]                49152
attention_layers.7.o_proj.bias                 [384]                  384
attention_layers.7.vec_proj.weight            [384, 128]                49152
attention_layers.7.dk_proj.weight             [128, 50]                 6400
attention_layers.7.dk_proj.bias                 [128]                  128
attention_layers.7.dv_proj.weight             [384, 50]                19200
attention_layers.7.dv_proj.bias                 [384]                  384
               out_norm.weight                 [128]                  128
                 out_norm.bias                 [128]                  128
        post_lin_list.0.weight             [64, 128]                 8192
          post_lin_list.0.bias                  [64]                   64
        post_lin_list.1.weight               [1, 64]                   64
          post_lin_list.1.bias                   [1]                    1
--------------------------------------------------------------------------
Total params: 1734629
Trainable params: 1734629
Non-trainable params: 0
Attempting to load checkpoint...
Recent checkpoint loaded successfully.
Settings: 
{'dataset': {'additional_attributes': ['forces', 'stress'],
             'data_format': 'json',
             'dataset_device': 'cpu',
             'name': 'MP_data_forces',
             'num_workers': 0,
             'prediction_level': 'graph',
             'preprocess_params': {'all_neighbors': True,
                                   'cutoff_radius': 8.0,
                                   'edge_calc_method': 'ocp',
                                   'edge_dim': 50,
                                   'n_neighbors': 250,
                                   'node_dim': 100,
                                   'node_representation': 'onehot',
                                   'num_offsets': 2,
                                   'preprocess_edge_features': False,
                                   'preprocess_edges': False,
                                   'preprocess_node_features': True,
                                   'self_loop': True},
             'processed': True,
             'pt_path': 'data/mp_data_forces/',
             'src': '/global/cfs/projectdirs/m3641/Shared/Materials_datasets/MP_data_forces/raw/data.json',
             'target_path': None,
             'test_ratio': 0.0,
             'train_ratio': 0.95,
             'transforms': [{'args': {'index': -1},
                             'name': 'GetY',
                             'otf': True}],
             'val_ratio': 0.05,
             'verbose': True},
 'model': {'activation': 'silu',
           'aggr': 'add',
           'attn_activation': 'silu',
           'dropout_rate': 0.0,
           'gradient': True,
           'hidden_channels': 128,
           'model_ensemble': 1,
           'name': 'torchmd_etEarly',
           'num_heads': 8,
           'num_layers': 8,
           'num_post_layers': 1,
           'num_rbf': 50,
           'otf_edge_attr': True,
           'otf_edge_index': True,
           'otf_node_attr': False,
           'pool': 'global_add_pool',
           'pool_order': 'late',
           'post_hidden_channels': 64,
           'prediction_level': 'graph'},
 'optim': {'batch_size': 32,
           'batch_tqdm': False,
           'clip_grad_norm': 10,
           'loss': {'loss_args': {'weight_energy': 0.01,
                                  'weight_force': 50.0,
                                  'weight_stress': 50.0},
                    'loss_type': 'ForceStressLoss'},
           'lr': 0.0001,
           'max_checkpoint_epochs': 0,
           'max_epochs': 400,
           'optimizer': {'optimizer_args': {}, 'optimizer_type': 'AdamW'},
           'scheduler': {'scheduler_args': {'factor': 0.8,
                                            'min_lr': 1e-05,
                                            'mode': 'min',
                                            'patience': 10,
                                            'threshold': 0.0002},
                         'scheduler_type': 'ReduceLROnPlateau'},
           'verbosity': 1},
 'submit': False,
 'task': {'checkpoint_path': 'results/torchmd-4-part1/checkpoint_0/checkpoint.pt',
          'continue_job': True,
          'identifier': 'matstructpredict-torchmd-4',
          'load_training_state': True,
          'log_id': '2024-02-27-06-41-15-063',
          'model_save_frequency': 1,
          'output_frequency': 1,
          'parallel': False,
          'run_mode': 'train',
          'save_dir': None,
          'seed': 13201867,
          'use_amp': True,
          'write_output': ['val']},
 'trainer': 'property'}
Starting regular training
Running for 45 epochs on TorchMD_ET model
Epoch: 0355, Learning Rate: 0.000033, Training Error: 1.98182, Val Error: 3.20247, Time per epoch (s): 1737.80437
Epoch: 0356, Learning Rate: 0.000026, Training Error: 1.93642, Val Error: 3.05676, Time per epoch (s): 1714.02374
Epoch: 0357, Learning Rate: 0.000026, Training Error: 1.92344, Val Error: 2.98831, Time per epoch (s): 1712.28062
Epoch: 0358, Learning Rate: 0.000026, Training Error: 1.80663, Val Error: 3.08325, Time per epoch (s): 1713.70508
Epoch: 0359, Learning Rate: 0.000026, Training Error: 1.89828, Val Error: 2.95945, Time per epoch (s): 1710.95312
Saving prediction results for epoch 360 to: /results/2024-02-27-06-41-19-144-matstructpredict-torchmd-4/train_results/
Saved val error: 2.94173
Epoch: 0360, Learning Rate: 0.000026, Training Error: 1.90919, Val Error: 2.95487, Time per epoch (s): 1712.19620
Saving prediction results for epoch 361 to: /results/2024-02-27-06-41-19-144-matstructpredict-torchmd-4/train_results/
Saved val error: 3.02003
Epoch: 0361, Learning Rate: 0.000026, Training Error: 1.82118, Val Error: 3.02542, Time per epoch (s): 1714.07050
Epoch: 0362, Learning Rate: 0.000026, Training Error: 1.89167, Val Error: 3.04286, Time per epoch (s): 1713.70887
Epoch: 0363, Learning Rate: 0.000026, Training Error: 1.89695, Val Error: 3.02503, Time per epoch (s): 1713.07403
Epoch: 0364, Learning Rate: 0.000026, Training Error: 1.89014, Val Error: 3.02812, Time per epoch (s): 1714.18196
Epoch: 0365, Learning Rate: 0.000026, Training Error: 1.83518, Val Error: 3.10795, Time per epoch (s): 1714.35001
Epoch: 0366, Learning Rate: 0.000026, Training Error: 1.85288, Val Error: 3.08753, Time per epoch (s): 1710.27434
Epoch: 0367, Learning Rate: 0.000026, Training Error: 1.87057, Val Error: 2.96497, Time per epoch (s): 1708.21039
Epoch: 0368, Learning Rate: 0.000026, Training Error: 1.86204, Val Error: 3.04824, Time per epoch (s): 1710.18555
Epoch: 0369, Learning Rate: 0.000026, Training Error: 1.84689, Val Error: 2.95272, Time per epoch (s): 1708.61125
Saving prediction results for epoch 370 to: /results/2024-02-27-06-41-19-144-matstructpredict-torchmd-4/train_results/
Saved val error: 3.04006
Epoch: 0370, Learning Rate: 0.000021, Training Error: 1.82784, Val Error: 2.99019, Time per epoch (s): 1711.29582
Epoch: 0371, Learning Rate: 0.000021, Training Error: 1.77311, Val Error: 2.96684, Time per epoch (s): 1710.42074
Epoch: 0372, Learning Rate: 0.000021, Training Error: 1.78839, Val Error: 3.03550, Time per epoch (s): 1715.97842
Epoch: 0373, Learning Rate: 0.000021, Training Error: 1.80765, Val Error: 3.05890, Time per epoch (s): 1711.08834
Epoch: 0374, Learning Rate: 0.000021, Training Error: 1.80131, Val Error: 3.02998, Time per epoch (s): 1712.16016
Epoch: 0375, Learning Rate: 0.000021, Training Error: 1.74475, Val Error: 2.91580, Time per epoch (s): 1709.69653
Saving prediction results for epoch 376 to: /results/2024-02-27-06-41-19-144-matstructpredict-torchmd-4/train_results/
Saved val error: 2.95903
Epoch: 0376, Learning Rate: 0.000021, Training Error: 1.79921, Val Error: 3.03940, Time per epoch (s): 1715.17196
Epoch: 0377, Learning Rate: 0.000021, Training Error: 1.80640, Val Error: 2.93997, Time per epoch (s): 1714.43609
Epoch: 0378, Learning Rate: 0.000021, Training Error: 1.78280, Val Error: 2.94817, Time per epoch (s): 1712.57346
Epoch: 0379, Learning Rate: 0.000021, Training Error: 1.78630, Val Error: 2.98670, Time per epoch (s): 1708.66837
Epoch: 0380, Learning Rate: 0.000021, Training Error: 1.79961, Val Error: 2.95624, Time per epoch (s): 1705.99972
Epoch: 0381, Learning Rate: 0.000021, Training Error: 1.79057, Val Error: 2.95810, Time per epoch (s): 1708.52940
Epoch: 0382, Learning Rate: 0.000021, Training Error: 1.76771, Val Error: 2.97128, Time per epoch (s): 1718.77142
Epoch: 0383, Learning Rate: 0.000021, Training Error: 1.78347, Val Error: 2.93997, Time per epoch (s): 1707.53991
Epoch: 0384, Learning Rate: 0.000021, Training Error: 1.79810, Val Error: 2.93511, Time per epoch (s): 1706.66718
Epoch: 0385, Learning Rate: 0.000021, Training Error: 1.76479, Val Error: 3.02233, Time per epoch (s): 1709.47041
Epoch: 0386, Learning Rate: 0.000021, Training Error: 1.79151, Val Error: 2.96824, Time per epoch (s): 1704.65619
Epoch: 0387, Learning Rate: 0.000017, Training Error: 1.73058, Val Error: 2.98598, Time per epoch (s): 1708.42713
Epoch: 0388, Learning Rate: 0.000017, Training Error: 1.74210, Val Error: 3.06934, Time per epoch (s): 1709.03113
Epoch: 0389, Learning Rate: 0.000017, Training Error: 1.74380, Val Error: 3.03265, Time per epoch (s): 1707.36680
Epoch: 0390, Learning Rate: 0.000017, Training Error: 1.72314, Val Error: 2.92451, Time per epoch (s): 1707.58643
Epoch: 0391, Learning Rate: 0.000017, Training Error: 1.72686, Val Error: 2.94548, Time per epoch (s): 1708.28330
Epoch: 0392, Learning Rate: 0.000017, Training Error: 1.76998, Val Error: 2.98129, Time per epoch (s): 1707.31442
Epoch: 0393, Learning Rate: 0.000017, Training Error: 1.70353, Val Error: 2.97749, Time per epoch (s): 1715.00193
Epoch: 0394, Learning Rate: 0.000017, Training Error: 1.72814, Val Error: 2.93391, Time per epoch (s): 1707.10068
Epoch: 0395, Learning Rate: 0.000017, Training Error: 1.73946, Val Error: 2.89928, Time per epoch (s): 1709.02749
Saving prediction results for epoch 396 to: /results/2024-02-27-06-41-19-144-matstructpredict-torchmd-4/train_results/
Saved val error: 2.90917
Epoch: 0396, Learning Rate: 0.000017, Training Error: 1.69768, Val Error: 2.94441, Time per epoch (s): 1699.11868
Epoch: 0397, Learning Rate: 0.000017, Training Error: 1.72975, Val Error: 2.96634, Time per epoch (s): 1698.92025
Epoch: 0398, Learning Rate: 0.000017, Training Error: 1.71446, Val Error: 2.99040, Time per epoch (s): 1699.09512
Epoch: 0399, Learning Rate: 0.000017, Training Error: 1.72899, Val Error: 2.97031, Time per epoch (s): 1702.26501
Final Losses: 
Saved val error: 2.94614
